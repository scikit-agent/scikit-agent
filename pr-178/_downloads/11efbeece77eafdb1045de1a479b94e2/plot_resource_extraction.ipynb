{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Resource Extraction Model\n\nThe resource extraction problem models the optimal management of a renewable\nresource (fishery, forest, wildlife, etc.). The decision-maker must balance\nimmediate profits from extraction against preserving the resource stock for\nfuture use.\n\nThis example implements the classic model from Reed (1979) [1]_, which shows that\nunder multiplicative environmental shocks and stock-dependent harvesting costs,\nthe optimal policy has a simple \"constant escapement\" form. The optimal\nescapement level can be computed analytically, making this an excellent benchmark\nfor testing reinforcement learning algorithms.\n\n## Model Structure\n\n- **State Variable**: $x_t$ \u2014 Resource stock level at time $t$\n- **Control Variable**: $u_t$ \u2014 Harvest/extraction rate (constrained: $0 \\leq u_t \\leq x_t$)\n\n### Dynamics\n\nThe resource stock evolves according to:\n\n\\begin{align}x_{t+1} = r(x_t - u_t) \\epsilon_t\\end{align}\n\nwhere:\n\n- $r > 1$ is the deterministic growth rate\n- $(x_t - u_t)$ is the **escapement** (stock remaining after harvest)\n- $\\epsilon_t$ is a multiplicative environmental shock with $\\mathbb{E}[\\epsilon_t] = 1$\n- $\\epsilon_t$ follows a log-normal distribution: $\\ln(\\epsilon_t) \\sim \\mathcal{N}(-\\sigma^2/2, \\sigma^2)$\n\n### Profit Function\n\nSingle-period profit is:\n\n\\begin{align}\\pi(u_t, x_t) = \\left(p - \\frac{c_0}{x_t}\\right) u_t\\end{align}\n\nwhere:\n\n- $p$ is the (constant) price per unit harvested\n- $c_0/x_t$ is the stock-dependent unit cost of harvesting\n\nThe cost specification captures the realistic feature that harvesting becomes\nmore expensive when the stock is depleted (e.g., fish are harder to catch when\npopulations are low).\n\n### Objective and Bellman Equation\n\nThe manager seeks to maximize expected discounted profit:\n\n\\begin{align}V(x_t) = \\max_{u_t} \\mathbb{E}\\left[\\pi(u_t, x_t) + \\delta V(x_{t+1})\\right]\\end{align}\n\nwhere $\\delta \\in (0,1)$ is the discount factor, which reflects time\npreference (impatience) and risk. The **Bellman equation** expresses the value\nof being in state $x_t$ as the maximum of current profit plus the\ndiscounted expected continuation value.\n\n### Parameters\n\n- $r$ = 1.1: Growth rate (10% per period)\n- $p$ = 5.0: Price per unit extracted\n- $c_0$ = 2.0: Cost parameter for stock-dependent costs\n- $\\delta$ (`DiscFac`) = 0.95: Discount factor for future rewards\n- $\\sigma$ = 0.1: Standard deviation of log-normal growth shock\n\n## Optimal Policy: Constant Escapement\n\nReed (1979) [1]_ proved that the optimal policy maintains a constant target stock\nlevel $S^*$ and harvests any surplus:\n\n\\begin{align}u_t^* = \\max(0, x_t - S^*)\\end{align}\n\nThe optimal escapement level is:\n\n\\begin{align}S^* = \\frac{c_0 (1 - \\delta)}{p (1 - \\delta r)}\\end{align}\n\nThis requires the \"impatience condition\" $\\delta r < 1$, which ensures\nthe agent prefers extraction over indefinite accumulation.\n\n### References\n\n.. [1] Reed, W.J. (1979). \"Optimal escapement levels in stochastic and\n       deterministic harvesting models.\" *Journal of Environmental Economics\n       and Management*, 6(4), 350-363.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport skagent as ska\nfrom skagent.distributions import Normal\nimport skagent.models.resource_extraction as rex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Inspection\n\nFirst, let's load the predefined model elements and inspect them.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Show Model Parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Model Calibration:\")\nfor param, value in rex.calibration.items():\n    print(f\"  {param}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Inspect the Resource Extraction Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rex.resource_extraction_block.display_formulas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Visualize the Resource Extraction Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img, _ = rex.resource_extraction_block.display(rex.calibration)\n\nplt.figure(figsize=(10, 8))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Compute Optimal Escapement Policy\n\nReed (1979) proved that the optimal policy has a **constant escapement** form:\n\n\\begin{align}u^*(x) = \\max(0, x - S^*)\\end{align}\n\nwhere $S^*$ is the optimal escapement level (target stock to maintain).\n\nThe optimal escapement can be computed analytically:\n\n\\begin{align}S^* = \\frac{c_0 (1 - \\delta)}{p (1 - \\delta r)}\\end{align}\n\nThis analytical solution makes the model ideal for validating reinforcement\nlearning algorithms\u2014we can compare learned policies against the known optimum.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dr_u, _ = rex.make_optimal_decision_rule(rex.calibration)\n\n# Compute S* for display\nr = rex.calibration[\"r\"]\np = rex.calibration[\"p\"]\nc_0 = rex.calibration[\"c_0\"]\ndelta = rex.calibration[\"DiscFac\"]\nS_star = c_0 * (1 - delta) / (p * (1 - delta * r))\n\nprint(f\"\\nOptimal escapement level: S* = {S_star:.4f}\")\nprint(f\"Optimal policy: u*(x) = max(0, x - {S_star:.4f})\")\n\n# Visualize the policy\nx_range = np.linspace(0, 5, 100)\nu_optimal = dr_u(x_range)\n\nplt.figure(figsize=(8, 5))\nplt.plot(x_range, u_optimal, label=r\"$u^*(x) = \\max(0, x - S^*)$\", linewidth=2)\nplt.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.3)\nplt.axvline(\n    x=S_star, color=\"r\", linestyle=\"--\", alpha=0.5, label=f\"$S^* = {S_star:.2f}$\"\n)\nplt.xlabel(\"Stock level (x)\")\nplt.ylabel(\"Optimal harvest (u*)\")\nplt.title(\"Reed's Constant Escapement Policy\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\n\n# Wrap rules in the format expected by simulator\ndecision_rule = {\"u\": dr_u}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 5: Run Monte Carlo Simulation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initial conditions - start with stock level around 2*S*\ninitial_conditions = {\n    \"x\": Normal(mu=2 * S_star, sigma=0.1),\n}\n\n# Create and run simulator\nsimulator = ska.MonteCarloSimulator(\n    calibration=rex.calibration,\n    block=rex.resource_extraction_block,\n    dr=decision_rule,\n    initial=initial_conditions,\n    agent_count=1000,  # Simulate 1000 agents\n    T_sim=100,  # For 100 periods\n    seed=42,  # For reproducibility\n)\n\n# Run the simulation\nprint(\"\\nRunning simulation...\")\nsimulator.initialize_sim()  # Initialize simulation variables\nsimulator.simulate()\n\nprint(\"\u2713 Simulation completed successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 6: Plot Simulation Results\n\nThe plot shows the distribution of stock levels over time under the optimal\nconstant escapement policy. The stock fluctuates around $S^*$ due to\nenvironmental shocks. When stock exceeds $S^*$, the surplus is harvested;\nwhen shocks drive stock below $S^*$, no harvest occurs and the stock\nrecovers through natural growth.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n\n# Plot percentiles to show distribution\nplt.fill_between(\n    range(simulator.T_sim),\n    np.percentile(simulator.history[\"x\"], 5, axis=1),\n    np.percentile(simulator.history[\"x\"], 95, axis=1),\n    alpha=0.2,\n    label=\"5th-95th percentile\",\n    color=\"C0\",\n)\nplt.fill_between(\n    range(simulator.T_sim),\n    np.percentile(simulator.history[\"x\"], 25, axis=1),\n    np.percentile(simulator.history[\"x\"], 75, axis=1),\n    alpha=0.3,\n    label=\"25th-75th percentile\",\n    color=\"C0\",\n)\nplt.plot(\n    simulator.history[\"x\"].mean(axis=1), label=\"Mean stock\", linewidth=2, color=\"C0\"\n)\n\n# Add reference line for optimal escapement\nplt.axhline(\n    y=S_star,\n    color=\"r\",\n    linestyle=\"--\",\n    linewidth=2,\n    label=f\"Optimal escapement $S^* = {S_star:.2f}$\",\n)\n\nplt.xlabel(\"Time period\", fontsize=11)\nplt.ylabel(\"Stock level (x)\", fontsize=11)\nplt.title(\"Resource Stock Evolution Under Optimal Escapement Policy\", fontsize=12)\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}