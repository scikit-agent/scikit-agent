
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/models/plot_resource_extraction.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_models_plot_resource_extraction.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_models_plot_resource_extraction.py:


############################
Resource Extraction Model
############################

The resource extraction problem models the optimal management of a renewable
resource (fishery, forest, wildlife, etc.). The decision-maker must balance
immediate profits from extraction against preserving the resource stock for
future use.

This example implements the classic model from Reed (1979) [1]_, which shows that
under multiplicative environmental shocks and stock-dependent harvesting costs,
the optimal policy has a simple "constant escapement" form. The optimal
escapement level can be computed analytically, making this an excellent benchmark
for testing reinforcement learning algorithms.

Model Structure
==================

- **State Variable**: :math:`x_t` — Resource stock level at time :math:`t`
- **Control Variable**: :math:`u_t` — Harvest/extraction rate (constrained: :math:`0 \leq u_t \leq x_t`)

Dynamics
--------

The resource stock evolves according to:

.. math::

    x_{t+1} = r(x_t - u_t) \epsilon_t

where:

- :math:`r > 1` is the deterministic growth rate
- :math:`(x_t - u_t)` is the **escapement** (stock remaining after harvest)
- :math:`\epsilon_t` is a multiplicative environmental shock with :math:`\mathbb{E}[\epsilon_t] = 1`
- :math:`\epsilon_t` follows a log-normal distribution: :math:`\ln(\epsilon_t) \sim \mathcal{N}(-\sigma^2/2, \sigma^2)`

Profit Function
---------------

Single-period profit is:

.. math::

    \pi(u_t, x_t) = \left(p - \frac{c_0}{x_t}\right) u_t

where:

- :math:`p` is the (constant) price per unit harvested
- :math:`c_0/x_t` is the stock-dependent unit cost of harvesting

The cost specification captures the realistic feature that harvesting becomes
more expensive when the stock is depleted (e.g., fish are harder to catch when
populations are low).

Objective and Bellman Equation
-------------------------------

The manager seeks to maximize expected discounted profit:

.. math::

    V(x_t) = \max_{u_t} \mathbb{E}\left[\pi(u_t, x_t) + \delta V(x_{t+1})\right]

where :math:`\delta \in (0,1)` is the discount factor, which reflects time
preference (impatience) and risk. The **Bellman equation** expresses the value
of being in state :math:`x_t` as the maximum of current profit plus the
discounted expected continuation value.

Parameters
----------

- :math:`r` = 1.1: Growth rate (10% per period)
- :math:`p` = 5.0: Price per unit extracted
- :math:`c_0` = 2.0: Cost parameter for stock-dependent costs
- :math:`\delta` (`DiscFac`) = 0.95: Discount factor for future rewards
- :math:`\sigma` = 0.1: Standard deviation of log-normal growth shock

Optimal Policy: Constant Escapement
====================================

Reed (1979) [1]_ proved that the optimal policy maintains a constant target stock
level :math:`S^*` and harvests any surplus:

.. math::

    u_t^* = \max(0, x_t - S^*)

The optimal escapement level is:

.. math::

    S^* = \frac{c_0 (1 - \delta)}{p (1 - \delta r)}

This requires the "impatience condition" :math:`\delta r < 1`, which ensures
the agent prefers extraction over indefinite accumulation.

References
----------

.. [1] Reed, W.J. (1979). "Optimal escapement levels in stochastic and
       deterministic harvesting models." *Journal of Environmental Economics
       and Management*, 6(4), 350-363.

.. GENERATED FROM PYTHON SOURCE LINES 107-114

.. code-block:: Python


    import matplotlib.pyplot as plt
    import numpy as np
    import skagent as ska
    from skagent.distributions import Normal
    import skagent.models.resource_extraction as rex








.. GENERATED FROM PYTHON SOURCE LINES 115-119

Model Inspection
-------------------

First, let's load the predefined model elements and inspect them.

.. GENERATED FROM PYTHON SOURCE LINES 121-123

Step 1: Show Model Parameters
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 123-128

.. code-block:: Python


    print("Model Calibration:")
    for param, value in rex.calibration.items():
        print(f"  {param}: {value}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model Calibration:
      r: 1.02
      p: 5.0
      c_0: 10.0
      DiscFac: 0.95
      sigma: 0.1




.. GENERATED FROM PYTHON SOURCE LINES 129-131

Step 2: Inspect the Resource Extraction Model
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 131-134

.. code-block:: Python


    rex.resource_extraction_block.display_formulas()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    u = Control(x)
    unit_cost = lambda x, c_0: c_0 / x
    profit = lambda u, p, unit_cost: (p - unit_cost) * u
    escapement = lambda x, u: x - u
    x = lambda escapement, r, epsilon: r * escapement * epsilon




.. GENERATED FROM PYTHON SOURCE LINES 135-137

Step 3: Visualize the Resource Extraction Model
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 137-145

.. code-block:: Python


    img, _ = rex.resource_extraction_block.display(rex.calibration)

    plt.figure(figsize=(10, 8))
    plt.imshow(img)
    plt.axis("off")
    plt.tight_layout()




.. image-sg:: /auto_examples/models/images/sphx_glr_plot_resource_extraction_001.png
   :alt: plot resource extraction
   :srcset: /auto_examples/models/images/sphx_glr_plot_resource_extraction_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    <IPython.core.display.SVG object>




.. GENERATED FROM PYTHON SOURCE LINES 146-166

Step 4: Compute Optimal Escapement Policy
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Reed (1979) proved that the optimal policy has a **constant escapement** form:

.. math::

    u^*(x) = \max(0, x - S^*)

where :math:`S^*` is the optimal escapement level (target stock to maintain).

The optimal escapement can be computed analytically:

.. math::

    S^* = \frac{c_0 (1 - \delta)}{p (1 - \delta r)}

This analytical solution makes the model ideal for validating reinforcement
learning algorithms—we can compare learned policies against the known optimum.


.. GENERATED FROM PYTHON SOURCE LINES 166-199

.. code-block:: Python


    dr_u, _ = rex.make_optimal_decision_rule(rex.calibration)

    # Compute S* for display
    r = rex.calibration["r"]
    p = rex.calibration["p"]
    c_0 = rex.calibration["c_0"]
    delta = rex.calibration["DiscFac"]
    S_star = c_0 * (1 - delta) / (p * (1 - delta * r))

    print(f"\nOptimal escapement level: S* = {S_star:.4f}")
    print(f"Optimal policy: u*(x) = max(0, x - {S_star:.4f})")

    # Visualize the policy
    x_range = np.linspace(0, 5, 100)
    u_optimal = dr_u(x_range)

    plt.figure(figsize=(8, 5))
    plt.plot(x_range, u_optimal, label=r"$u^*(x) = \max(0, x - S^*)$", linewidth=2)
    plt.axhline(y=0, color="k", linestyle="--", alpha=0.3)
    plt.axvline(
        x=S_star, color="r", linestyle="--", alpha=0.5, label=f"$S^* = {S_star:.2f}$"
    )
    plt.xlabel("Stock level (x)")
    plt.ylabel("Optimal harvest (u*)")
    plt.title("Reed's Constant Escapement Policy")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    # Wrap rules in the format expected by simulator
    decision_rule = {"u": dr_u}




.. image-sg:: /auto_examples/models/images/sphx_glr_plot_resource_extraction_002.png
   :alt: Reed's Constant Escapement Policy
   :srcset: /auto_examples/models/images/sphx_glr_plot_resource_extraction_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Optimal escapement level: S* = 3.2258
    Optimal policy: u*(x) = max(0, x - 3.2258)




.. GENERATED FROM PYTHON SOURCE LINES 200-202

Step 5: Run Monte Carlo Simulation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 202-226

.. code-block:: Python


    # Initial conditions - start with stock level around 2*S*
    initial_conditions = {
        "x": Normal(mu=2 * S_star, sigma=0.1),
    }

    # Create and run simulator
    simulator = ska.MonteCarloSimulator(
        calibration=rex.calibration,
        block=rex.resource_extraction_block,
        dr=decision_rule,
        initial=initial_conditions,
        agent_count=1000,  # Simulate 1000 agents
        T_sim=100,  # For 100 periods
        seed=42,  # For reproducibility
    )

    # Run the simulation
    print("\nRunning simulation...")
    simulator.initialize_sim()  # Initialize simulation variables
    simulator.simulate()

    print("✓ Simulation completed successfully")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Running simulation...
    ✓ Simulation completed successfully




.. GENERATED FROM PYTHON SOURCE LINES 227-235

Step 6: Plot Simulation Results
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The plot shows the distribution of stock levels over time under the optimal
constant escapement policy. The stock fluctuates around :math:`S^*` due to
environmental shocks. When stock exceeds :math:`S^*`, the surplus is harvested;
when shocks drive stock below :math:`S^*`, no harvest occurs and the stock
recovers through natural growth.

.. GENERATED FROM PYTHON SOURCE LINES 235-275

.. code-block:: Python


    plt.figure(figsize=(10, 6))

    # Plot percentiles to show distribution
    plt.fill_between(
        range(simulator.T_sim),
        np.percentile(simulator.history["x"], 5, axis=1),
        np.percentile(simulator.history["x"], 95, axis=1),
        alpha=0.2,
        label="5th-95th percentile",
        color="C0",
    )
    plt.fill_between(
        range(simulator.T_sim),
        np.percentile(simulator.history["x"], 25, axis=1),
        np.percentile(simulator.history["x"], 75, axis=1),
        alpha=0.3,
        label="25th-75th percentile",
        color="C0",
    )
    plt.plot(
        simulator.history["x"].mean(axis=1), label="Mean stock", linewidth=2, color="C0"
    )

    # Add reference line for optimal escapement
    plt.axhline(
        y=S_star,
        color="r",
        linestyle="--",
        linewidth=2,
        label=f"Optimal escapement $S^* = {S_star:.2f}$",
    )

    plt.xlabel("Time period", fontsize=11)
    plt.ylabel("Stock level (x)", fontsize=11)
    plt.title("Resource Stock Evolution Under Optimal Escapement Policy", fontsize=12)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()



.. image-sg:: /auto_examples/models/images/sphx_glr_plot_resource_extraction_003.png
   :alt: Resource Stock Evolution Under Optimal Escapement Policy
   :srcset: /auto_examples/models/images/sphx_glr_plot_resource_extraction_003.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 4.229 seconds)


.. _sphx_glr_download_auto_examples_models_plot_resource_extraction.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_resource_extraction.ipynb <plot_resource_extraction.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_resource_extraction.py <plot_resource_extraction.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_resource_extraction.zip <plot_resource_extraction.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
