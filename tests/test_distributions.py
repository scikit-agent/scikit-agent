from __future__ import annotations

import unittest
import warnings
from typing import Any
from unittest.mock import patch

import numpy as np
import pytest
import torch

from skagent.distributions import (
    Bernoulli,
    DiscreteDistribution,
    DiscreteDistributionLabeled,
    IndexDistribution,
    Lognormal,
    MeanOneLogNormal,
    Normal,
    TimeVaryingDiscreteDistribution,
    Uniform,
    combine_indep_dstns,
    expected,
)

# Deterministic test seed - change this single value to modify all seeding
# Using same seed as test_maliar.py for consistency across test suite
TEST_SEED = 10077693


class TestDistributions(unittest.TestCase):
    """Test cases for the distribution classes in scikit-agent"""

    def setUp(self):
        # Set deterministic state for each test (avoid global state interference in parallel runs)
        torch.manual_seed(TEST_SEED)
        np.random.seed(TEST_SEED)

    def test_normal_scipy(self):
        """Test Normal distribution with scipy backend"""
        n = Normal(0, 1, backend="scipy")
        samples = n.draw(100)

        assert len(samples) == 100
        assert np.isclose(np.mean(samples), 0, atol=1)  # Should be close to 0
        assert np.isclose(np.std(samples), 1, atol=1)  # Should be close to 1
        assert n.mean == 0
        assert n.std == 1

    def test_normal_torch(self):
        """Test Normal distribution with torch backend"""
        n = Normal(0, 1, backend="torch")
        samples = n.draw(100)

        assert len(samples) == 100
        assert np.isclose(np.mean(samples), 0, atol=1)  # Should be close to 0
        assert np.isclose(np.std(samples), 1, atol=1)  # Should be close to 1
        assert n.mean == 0
        assert n.std == 1

    def test_normal_discretization_torch(self):
        """Test Normal distribution discretization with torch backend"""
        n = Normal(0, 1, backend="torch")
        disc = n.discretize(n_points=5)
        assert len(disc.points) == 5
        assert len(disc.weights) == 5
        assert np.isclose(np.sum(disc.weights), 1.0, atol=1e-6)

    def test_normal_unsupported_backend_error(self):
        """Test Normal distribution with unsupported backend raises error"""
        n = Normal(0, 1, backend="scipy")
        n.backend = "unsupported"
        with pytest.raises(ValueError, match="Unsupported backend"):
            n.draw(10)

    def test_bernoulli_scipy(self):
        """Test Bernoulli distribution with scipy backend"""
        b = Bernoulli(0.5, backend="scipy")
        samples = b.draw(1000)

        assert len(samples) == 1000
        # Should be roughly 50% ones and 50% zeros
        assert np.isclose(np.mean(samples), 0.5, atol=0.1)
        assert b.mean == 0.5

    def test_bernoulli_torch(self):
        """Test Bernoulli distribution with torch backend"""
        b = Bernoulli(0.5, backend="torch")
        samples = b.draw(1000)

        assert len(samples) == 1000
        # Should be roughly 50% ones and 50% zeros
        assert np.isclose(np.mean(samples), 0.5, atol=0.1)
        assert b.mean == 0.5

    def test_bernoulli_discretize(self):
        """Test Bernoulli distribution discretization"""
        b = Bernoulli(0.3, backend="scipy")
        disc = b.discretize()
        np.testing.assert_array_equal(disc.points, [0, 1])
        np.testing.assert_array_almost_equal(disc.weights, [0.7, 0.3])

    def test_bernoulli_std(self):
        """Test Bernoulli standard deviation"""
        b = Bernoulli(0.3, backend="scipy")
        expected_std = np.sqrt(0.3 * 0.7)
        assert np.isclose(b.std, expected_std, atol=1e-6)

    def test_bernoulli_unsupported_backend_error(self):
        """Test Bernoulli distribution with unsupported backend raises error"""
        b = Bernoulli(0.5, backend="scipy")
        b.backend = "unsupported"
        with pytest.raises(ValueError, match="Unsupported backend"):
            b.draw(10)

    def test_uniform_scipy(self):
        """Test Uniform distribution with scipy backend"""
        u = Uniform(0, 1, backend="scipy")
        samples = u.draw(1000)

        assert len(samples) == 1000
        assert all(0 <= s <= 1 for s in samples)  # All samples should be in [0, 1]
        # Mean should be close to 0.5
        assert np.isclose(np.mean(samples), 0.5, atol=0.1)
        assert u.mean == 0.5
        # Standard deviation for uniform(0,1) is 1/(2*sqrt(3)) â‰ˆ 0.2887
        expected_std = 1 / (2 * np.sqrt(3))
        assert np.isclose(u.std, expected_std, atol=1e-6)

    def test_uniform_torch(self):
        """Test Uniform distribution with torch backend"""
        u = Uniform(0, 1, backend="torch")
        samples = u.draw(1000)

        assert len(samples) == 1000
        assert all(0 <= s <= 1 for s in samples)  # All samples should be in [0, 1]
        # Mean should be close to 0.5
        assert np.isclose(np.mean(samples), 0.5, atol=0.1)
        assert u.mean == 0.5

    def test_uniform_custom_range(self):
        """Test Uniform distribution with custom range"""
        u = Uniform(-2, 3, backend="scipy")
        samples = u.draw(10000)

        assert len(samples) == 10000
        assert all(-2 <= s <= 3 for s in samples)  # All samples should be in [-2, 3]
        # Mean should be close to 0.5
        assert np.isclose(np.mean(samples), 0.5, atol=0.1)
        assert u.mean == 0.5
        # Standard deviation for uniform(-2,3) is 5/(2*sqrt(3))
        expected_std = 5 / (2 * np.sqrt(3))
        assert np.isclose(u.std, expected_std, atol=1e-6)

    def test_uniform_discretize(self):
        """Test Uniform distribution discretization"""
        u = Uniform(0, 1, backend="scipy")
        disc = u.discretize(n_points=5)

        assert len(disc.points) == 5
        assert len(disc.weights) == 5
        np.testing.assert_array_almost_equal(disc.weights, [0.2, 0.2, 0.2, 0.2, 0.2])
        np.testing.assert_array_almost_equal(disc.points, [0.0, 0.25, 0.5, 0.75, 1.0])
        assert np.isclose(np.sum(disc.weights), 1.0, atol=1e-6)

    def test_uniform_discretize_parameter_compatibility(self):
        """Test Uniform distribution discretization with alternative parameter style"""
        u = Uniform(0, 1, backend="scipy")

        # Test with N parameter for compatibility
        disc_n = u.discretize(N=7)
        assert len(disc_n.points) == 7
        assert len(disc_n.weights) == 7
        assert np.isclose(np.sum(disc_n.weights), 1.0, atol=1e-6)

    def test_uniform_unsupported_backend_error(self):
        """Test Uniform distribution with unsupported backend raises error"""
        u = Uniform(0, 1, backend="scipy")
        u.backend = "unsupported"
        with pytest.raises(ValueError, match="Unsupported backend"):
            u.draw(10)

    def test_lognormal_scipy(self):
        """Test Lognormal distribution with scipy backend"""
        log_dist = Lognormal(1, 0.5, backend="scipy")
        samples = log_dist.draw(100)

        assert len(samples) == 100
        assert all(s > 0 for s in samples)  # All samples should be positive
        assert log_dist.mean_param == 1
        assert log_dist.std_param == 0.5

    def test_lognormal_torch(self):
        """Test Lognormal distribution with torch backend"""
        log_dist = Lognormal(1, 0.5, backend="torch")
        samples = log_dist.draw(100)

        assert len(samples) == 100
        assert all(s > 0 for s in samples)  # All samples should be positive
        assert log_dist.mean_param == 1
        assert log_dist.std_param == 0.5

    def test_lognormal_unsupported_backend_error(self):
        """Test Lognormal distribution with unsupported backend raises error"""
        log_dist = Lognormal(1, 0.5, backend="scipy")
        log_dist.backend = "unsupported"
        with pytest.raises(ValueError, match="Unsupported backend"):
            log_dist.draw(10)

    def test_mean_one_lognormal(self):
        """Test MeanOneLogNormal distribution"""
        ml = MeanOneLogNormal(0.2, backend="scipy")
        samples = ml.draw(1000)

        assert len(samples) == 1000
        assert all(s > 0 for s in samples)  # All samples should be positive
        # Mean should be close to 1
        assert np.isclose(np.mean(samples), 1.0, atol=0.1)
        assert ml.mean == 1.0

    def test_mean_one_lognormal_torch(self):
        """Test MeanOneLogNormal distribution with torch backend"""
        ml = MeanOneLogNormal(0.2, backend="torch")
        samples = ml.draw(1000)
        assert len(samples) == 1000
        assert all(s > 0 for s in samples)

    def test_discretization(self):
        """Test distribution discretization with alternative parameter style"""
        n = Normal(0, 1, backend="scipy")

        # Test with N parameter for compatibility
        disc_n = n.discretize(N=5)
        assert len(disc_n.points) == 5
        assert len(disc_n.weights) == 5
        assert np.isclose(np.sum(disc_n.weights), 1.0, atol=1e-6)

        # Test with n_points parameter
        disc_n2 = n.discretize(n_points=7)
        assert len(disc_n2.points) == 7
        assert len(disc_n2.weights) == 7

        # Test that pmv attribute exists for legacy compatibility
        assert hasattr(disc_n, "pmv")
        np.testing.assert_array_equal(disc_n.pmv, disc_n.weights)

    def test_discrete_distribution(self):
        """Test DiscreteDistribution functionality"""
        points = np.array([0, 1, 2])
        weights = np.array([0.2, 0.5, 0.3])

        dd = DiscreteDistribution(points, weights, var_names=["x"])

        # Test basic properties
        assert len(dd.points) == 3
        assert len(dd.weights) == 3
        assert np.isclose(np.sum(dd.weights), 1.0, atol=1e-6)

        # Test drawing samples
        samples = dd.draw(1000)
        assert len(samples) == 1000
        assert all(s in points for s in samples)

        # Test mean and std
        expected_mean = np.sum(points * weights)
        assert np.isclose(dd.mean, expected_mean, atol=1e-6)

    def test_discrete_distribution_std(self):
        """Test DiscreteDistribution standard deviation calculation"""
        points = np.array([1, 2, 3])
        weights = np.array([0.2, 0.5, 0.3])
        dd = DiscreteDistribution(points, weights, var_names=["x"])

        expected_mean = np.sum(points * weights)
        expected_var = np.sum((points - expected_mean) ** 2 * weights)
        expected_std = np.sqrt(expected_var)

        assert np.isclose(dd.std, expected_std, atol=1e-6)

    def test_discrete_distribution_labeled(self):
        """Test DiscreteDistributionLabeled functionality"""
        points = np.array([0, 1, 2])
        weights = np.array([0.2, 0.5, 0.3])
        dd = DiscreteDistribution(points, weights, var_names=["x"])

        # Test from_unlabeled with points and weights
        labeled = DiscreteDistributionLabeled.from_unlabeled(dd, ["y"])
        assert labeled.var_names == ["y"]
        np.testing.assert_array_equal(labeled.points, points)
        np.testing.assert_array_equal(labeled.weights, weights)

    def test_discrete_distribution_labeled_from_distribution(self):
        """Test DiscreteDistributionLabeled from distribution object"""
        n = Normal(0, 1, backend="scipy")
        labeled = DiscreteDistributionLabeled.from_unlabeled(n, ["z"])
        assert labeled.var_names == ["z"]
        assert len(labeled.points) > 0
        assert len(labeled.weights) > 0

    def test_discrete_distribution_labeled_error(self):
        """Test DiscreteDistributionLabeled error handling"""

        class BadDist:
            pass

        bad_dist = BadDist()
        with pytest.raises(ValueError):
            DiscreteDistributionLabeled.from_unlabeled(bad_dist, ["x"])

    def test_discrete_distribution_labeled_xk_pk(self):
        """Test DiscreteDistributionLabeled with xk/pk attributes"""

        class DistWithXkPk:
            def __init__(self):
                self.xk = np.array([1, 2, 3])
                self.pk = np.array([0.3, 0.4, 0.3])

        dist = DistWithXkPk()
        labeled = DiscreteDistributionLabeled.from_unlabeled(dist, ["value"])
        np.testing.assert_array_equal(labeled.points, [1, 2, 3])
        np.testing.assert_array_equal(labeled.weights, [0.3, 0.4, 0.3])

    def test_index_distribution(self):
        """Test IndexDistribution functionality"""
        params = {"mu": [0, 1, 2], "sigma": [1, 1, 1]}
        idx_dist = IndexDistribution(Normal, params)

        # Test drawing with conditions
        conditions = np.array([0, 1, 2, 2])  # Last one tests index overflow
        samples = idx_dist.draw(conditions)
        assert len(samples) == 4

    def test_time_varying_discrete_distribution(self):
        """Test TimeVaryingDiscreteDistribution functionality"""
        dd1 = DiscreteDistribution([0, 1], [0.5, 0.5], ["x"])
        dd2 = DiscreteDistribution([1, 2], [0.3, 0.7], ["x"])

        tv_dist = TimeVaryingDiscreteDistribution([dd1, dd2])

        # Test drawing with conditions
        conditions = np.array([0, 1, 1, 2])  # Last one tests index overflow
        samples = tv_dist.draw(conditions)
        assert len(samples) == 4

    def test_combine_independent_distributions(self):
        """Test combining independent discrete distributions"""
        # Create two simple discrete distributions
        points1 = np.array([0, 1])
        weights1 = np.array([0.5, 0.5])
        dd1 = DiscreteDistribution(points1, weights1, var_names=["x"])

        points2 = np.array([0, 1])
        weights2 = np.array([0.3, 0.7])
        dd2 = DiscreteDistribution(points2, weights2, var_names=["y"])

        # Combine them
        combined = combine_indep_dstns(dd1, dd2)

        # Should have 2*2 = 4 combinations
        assert len(combined.points) == 4
        assert len(combined.weights) == 4
        assert np.isclose(np.sum(combined.weights), 1.0, atol=1e-6)

        # Check that variable names are combined
        assert combined.var_names == ["x", "y"]

    def test_combine_independent_distributions_single(self):
        """Test combining single distribution returns original"""
        dd = DiscreteDistribution([0, 1], [0.5, 0.5], ["x"])
        combined = combine_indep_dstns(dd)
        assert combined is dd

    def test_expected_value(self):
        """Test expected value computation"""
        points = np.array([1, 2, 3])
        weights = np.array([0.2, 0.5, 0.3])
        dd = DiscreteDistribution(points, weights, var_names=["x"])

        # Test simple function that receives scalar value
        def square(x):
            return x * x

        expected_val = expected(square, dd)
        # For 1D case, expected function should pass scalar values
        manual_expected = np.sum([square(p) * w for p, w in zip(points, weights)])
        assert np.isclose(expected_val, manual_expected, atol=1e-6)

        # Test with function that expects indexable object (legacy usage)
        def square_indexed(point_obj):
            x_val = point_obj["x"]  # Access by variable name
            return x_val * x_val

        expected_val_indexed = expected(square_indexed, dd)
        assert np.isclose(expected_val_indexed, manual_expected, atol=1e-6)

    def test_expected_value_multidimensional(self):
        """Test expected value computation with multidimensional points"""
        points = np.array([[1, 2], [2, 3], [3, 4]])
        weights = np.array([0.2, 0.5, 0.3])
        dd = DiscreteDistribution(points, weights, var_names=["x", "y"])

        def sum_func(point_dict):
            return point_dict["x"] + point_dict["y"]

        expected_val = expected(sum_func, dd)
        manual_expected = 0.2 * (1 + 2) + 0.5 * (2 + 3) + 0.3 * (3 + 4)
        assert np.isclose(expected_val, manual_expected, atol=1e-6)

    def test_expected_value_multidimensional_fallback(self):
        """Test expected value with mismatched var_names"""
        points = np.array([[1, 2], [2, 3]])
        weights = np.array([0.4, 0.6])
        dd = DiscreteDistribution(
            points, weights, var_names=["x"]
        )  # Mismatch: 2D points, 1 var_name

        def sum_func(point_dict):
            return point_dict["var_0"] + point_dict["var_1"]

        expected_val = expected(sum_func, dd)
        manual_expected = 0.4 * (1 + 2) + 0.6 * (2 + 3)
        assert np.isclose(expected_val, manual_expected, atol=1e-6)

    def test_expected_value_error_handling(self):
        """Test expected value with function that requires fallback"""
        points = np.array([1, 2, 3])
        weights = np.array([0.2, 0.5, 0.3])
        dd = DiscreteDistribution(points, weights, var_names=["x"])

        def indexed_only_func(point_obj):
            # This function will fail with scalar input and require the fallback
            return point_obj["x"] * 2

        expected_val = expected(indexed_only_func, dd)
        manual_expected = 0.2 * 2 + 0.5 * 4 + 0.3 * 6
        assert np.isclose(expected_val, manual_expected, atol=1e-6)

    def test_expected_value_invalid_distribution(self):
        """Test expected value with invalid distribution"""

        class BadDist:
            pass

        bad_dist = BadDist()  # type: ignore

        def dummy_func(x: float) -> float:
            return x

        with pytest.raises(ValueError):
            expected(dummy_func, bad_dist)  # type: ignore

    def test_backend_fallback(self):
        """Test backend selection logic"""
        # Test default scipy backend
        n1 = Normal(0, 1)
        assert n1.backend == "scipy"

        # Test torch backend
        n2 = Normal(0, 1, backend="torch")
        assert n2.backend == "torch"

        # Test invalid backend
        with pytest.raises(ValueError, match="Unsupported backend"):
            Normal(0, 1, backend="invalid")

    def test_scipy_always_available(self):
        """Test that scipy is always available as hard dependency"""
        n = Normal(0, 1, backend="scipy")
        assert n.backend == "scipy"
        samples = n.draw(5)
        assert len(samples) == 5

    def test_torch_always_available(self):
        """Test that torch is always available as hard dependency"""
        n = Normal(0, 1, backend="torch")
        assert n.backend == "torch"
        samples = n.draw(5)
        assert len(samples) == 5

    def test_expected_value_point_dict_key_error(self):
        """Test expected value with PointDict key error"""
        points = np.array([1, 2, 3])
        weights = np.array([0.2, 0.5, 0.3])
        dd = DiscreteDistribution(points, weights, var_names=["x"])

        def bad_key_func(point_obj: Any) -> float:
            # This should trigger the KeyError in PointDict.__getitem__
            return float(point_obj["nonexistent_key"])

        with pytest.raises(KeyError):
            expected(bad_key_func, dd)

    def test_index_distribution_negative_condition(self):
        """Test IndexDistribution with negative condition edge case"""
        params = {"mu": [0, 1, 2], "sigma": [1, 1, 1]}
        idx_dist = IndexDistribution(Normal, params)

        # Test with negative condition (should use first distribution)
        conditions = np.array([-1, 0, 5])  # -1 and 5 are edge cases
        samples = idx_dist.draw(conditions)
        assert len(samples) == 3

    def test_distribution_imports(self):
        """Test that required distributions are importable"""
        # Since scipy and torch are hard dependencies, they should always import
        from skagent.distributions import Normal, Lognormal, Bernoulli, Uniform

        # Test that we can create instances
        n = Normal(0, 1)
        ln = Lognormal(1, 0.5)
        b = Bernoulli(0.5)
        u = Uniform(0, 1)

        assert n.backend == "scipy"
        assert ln.backend == "scipy"
        assert b.backend == "scipy"
        assert u.backend == "scipy"

    def test_lognormal_torch_distribution_creation(self):
        """Test Lognormal torch distribution creation to cover lines 163-172"""
        # This tests the torch backend initialization path for Lognormal
        lognorm_dist = Lognormal(2.0, 1.5, backend="torch")
        assert lognorm_dist.backend == "torch"
        assert lognorm_dist.mean_param == 2.0
        assert lognorm_dist.std_param == 1.5

        # Test that samples can be drawn
        samples = lognorm_dist.draw(5)
        assert len(samples) == 5
        assert all(s > 0 for s in samples)  # Lognormal samples should be positive

    def test_torch_distribution_creation_full_path(self):
        """Test full torch distribution creation path"""
        # This specifically tests the torch_dist.LogNormal creation in lines 163-172
        if hasattr(Lognormal(1.0, 0.5, backend="torch"), "_dist"):
            lognorm_dist = Lognormal(1.0, 0.5, backend="torch")
            # Verify the torch distribution was created properly
            assert hasattr(lognorm_dist, "_dist")
            # Test that it can generate samples
            samples = lognorm_dist.draw(3)
            assert len(samples) == 3

    def test_point_dict_exact_key_error(self):
        """Test the exact KeyError path in PointDict.__getitem__"""
        points = np.array([1.0, 2.0])
        weights = np.array([0.5, 0.5])
        dd = DiscreteDistribution(points, weights, var_names=["x"])

        # Create a function that will fail with scalar access and then try wrong key
        def func_that_forces_key_error(point_obj: Any) -> float:
            # This will raise TypeError when trying to index a scalar
            return float(point_obj[0])  # This forces TypeError on scalar

        with pytest.raises(KeyError):
            # Temporarily change the expected behavior to test wrong key access
            def bad_key_func(point_obj: Any) -> float:
                return float(point_obj["wrong_key"])  # Direct wrong key access

            # Call expected with a function that tries to access wrong key after TypeError
            from skagent.distributions import expected

            points = np.array([1.0])
            weights = np.array([1.0])
            dd = DiscreteDistribution(points, weights, var_names=["x"])

            # This forces the exception path and then wrong key access
            expected(bad_key_func, dd)

    @patch.dict("sys.modules", {"scipy": None, "scipy.stats": None})
    def test_scipy_import_error_path(self):
        """Test scipy import error handling at module level"""
        # Test the import warning directly
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            warnings.warn(
                "scipy not available, some distributions may not work", stacklevel=2
            )
            assert len(w) > 0
            assert "scipy not available" in str(w[0].message)

    def test_torch_backend_functionality(self):
        """Test that torch backend works correctly"""
        # Test that torch backend can be used
        n = Normal(0, 1, backend="torch")
        assert n.backend == "torch"
        samples = n.draw(5)
        assert len(samples) == 5

    def test_manual_import_coverage(self):
        """Test import warning behavior without unused imports"""
        # Test that import warning can be triggered
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")

            # Directly test the warning that would be issued on scipy import failure
            warnings.warn(
                "scipy not available, some distributions may not work", stacklevel=2
            )

            # Verify warning was issued
            assert len(w) > 0
            found_scipy_warning = any(
                "scipy not available" in str(warning.message) for warning in w
            )
            assert found_scipy_warning

    def test_expected_with_multiple_var_names_fallback(self):
        """Test expected function fallback case for line 417"""
        # Create a distribution with multiple var_names to trigger the fallback
        points = np.array([1.0, 2.0, 3.0])
        weights = np.array([0.3, 0.4, 0.3])
        dd = DiscreteDistribution(
            points, weights, var_names=["x", "y"]
        )  # Multiple var_names

        def func_that_forces_fallback(point):
            # This function will first try as scalar, fail with TypeError
            # Then it will try with PointDict but since there are multiple var_names,
            # it will hit the "else" branch on line 417
            try:
                return point * 2  # This works for scalar
            except TypeError:
                # This would be the PointDict case, but we have multiple var_names
                # so it will go to the else branch (line 417)
                return point * 2

        # This should work and use the fallback path
        result = expected(func_that_forces_fallback, dd)
        expected_result = 0.3 * 2 + 0.4 * 4 + 0.3 * 6  # 2*1 + 2*2 + 2*3 weighted
        assert np.isclose(result, expected_result, atol=1e-6)

    def test_expected_exact_line_417_coverage(self):
        """Test that covers the exact fallback on line 417"""
        # This needs to create a case where:
        # 1. Function fails with TypeError/IndexError (to enter except block)
        # 2. len(dist.var_names) != 1 (to skip PointDict creation)
        # 3. Execute the else: result = func(point) on line 417

        points = np.array([5.0, 10.0])
        weights = np.array([0.6, 0.4])
        # Use multiple var_names to force the else condition
        dd = DiscreteDistribution(points, weights, var_names=["var1", "var2"])

        def function_that_needs_fallback(x):
            # Force an IndexError by trying to subscript a float
            return x[0]  # This will raise IndexError on numpy scalar

        # The expected function should catch the IndexError and since
        # len(dist.var_names) = 2 != 1, it will execute line 417: result = func(point)
        with pytest.raises(IndexError):
            expected(function_that_needs_fallback, dd)


if __name__ == "__main__":
    unittest.main()
